{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b825ac2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torchvision.transforms as transforms\n",
    "from torchvision.models import vgg16\n",
    "try:\n",
    "    from torchvision.models import VGG16_Weights\n",
    "    vgg_weights = VGG16_Weights.IMAGENET1K_V1\n",
    "except ImportError:\n",
    "    vgg_weights = None\n",
    "\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "import os\n",
    "from skimage.color import rgb2lab, lab2rgb\n",
    "from skimage.metrics import peak_signal_noise_ratio as psnr\n",
    "from skimage.metrics import structural_similarity as ssim\n",
    "import lpips\n",
    "from colormath.color_objects import LabColor, sRGBColor\n",
    "from colormath.color_conversions import convert_color\n",
    "from colormath.color_diff import delta_e_cie2000\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "import warnings\n",
    "\n",
    "warnings.filterwarnings('ignore', category=RuntimeWarning)\n",
    "\n",
    "if not hasattr(np, 'asscalar'):\n",
    "    np.asscalar = lambda x: x.item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "127122bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configuration\n",
    "MODEL_ID = 'C_lambda1_0.5x'\n",
    "USE_GAN = True\n",
    "USE_L1 = True\n",
    "USE_PERCEPTUAL = True\n",
    "LAMBDA_L1 = 50.0  # 0.5× baseline\n",
    "LAMBDA_PERCEPTUAL = 10.0\n",
    "\n",
    "BATCH_SIZE = 64\n",
    "NUM_EPOCHS = 50\n",
    "LEARNING_RATE = 2e-4\n",
    "IMAGE_SIZE = 256\n",
    "NUM_WORKERS = 4\n",
    "\n",
    "DATA_DIR = '../data/colorize_dataset/data'\n",
    "MODEL_DIR = f'../models/{MODEL_ID}'\n",
    "RESULTS_DIR = '../results'\n",
    "\n",
    "os.makedirs(MODEL_DIR, exist_ok=True)\n",
    "os.makedirs(RESULTS_DIR, exist_ok=True)\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    device = torch.device('cuda')\n",
    "elif torch.backends.mps.is_available():\n",
    "    device = torch.device('mps')\n",
    "else:\n",
    "    device = torch.device('cpu')\n",
    "print(f'Using device: {device}')\n",
    "print(f'Lambda L1: {LAMBDA_L1} (0.5× baseline)')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "650f0a58",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ColorizeDataset(Dataset):\n",
    "    def __init__(self, color_dir, size=256, split='train'):\n",
    "        self.color_dir = color_dir\n",
    "        self.size = size\n",
    "        self.split = split\n",
    "        self.images = [f for f in os.listdir(color_dir) if f.endswith(('.jpg', '.jpeg', '.png'))]\n",
    "        \n",
    "        if split == 'train':\n",
    "            self.transform = transforms.Compose([\n",
    "                transforms.Resize((size, size)),\n",
    "                transforms.RandomHorizontalFlip(p=0.5),\n",
    "                transforms.RandomRotation(degrees=15),\n",
    "                transforms.ColorJitter(brightness=0.2, contrast=0.2, saturation=0.2, hue=0.1),\n",
    "                transforms.RandomAffine(degrees=0, translate=(0.1, 0.1)),\n",
    "                transforms.ToTensor()\n",
    "            ])\n",
    "        else:\n",
    "            self.transform = transforms.Compose([\n",
    "                transforms.Resize((size, size)),\n",
    "                transforms.ToTensor()\n",
    "            ])\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.images)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        img_path = os.path.join(self.color_dir, self.images[idx])\n",
    "        img = Image.open(img_path).convert('RGB')\n",
    "        img = self.transform(img)\n",
    "        \n",
    "        img_np = img.permute(1, 2, 0).numpy()\n",
    "        lab = rgb2lab(img_np)\n",
    "        \n",
    "        L = lab[:, :, 0] / 50.0 - 1.0\n",
    "        ab = lab[:, :, 1:] / 110.0\n",
    "        \n",
    "        L = torch.from_numpy(L).float().unsqueeze(0)\n",
    "        ab = torch.from_numpy(ab).float().permute(2, 0, 1)\n",
    "        \n",
    "        return L, ab\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af142ec7",
   "metadata": {},
   "outputs": [],
   "source": [
    "class UNetBlock(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels, down=True, use_dropout=False, use_batchnorm=True):\n",
    "        super(UNetBlock, self).__init__()\n",
    "        self.conv = nn.Sequential(\n",
    "            nn.Conv2d(in_channels, out_channels, 4, 2, 1, bias=False) if down \n",
    "            else nn.ConvTranspose2d(in_channels, out_channels, 4, 2, 1, bias=False),\n",
    "            nn.BatchNorm2d(out_channels) if use_batchnorm else nn.Identity(),\n",
    "            nn.Dropout(0.5) if use_dropout else nn.Identity(),\n",
    "            nn.LeakyReLU(0.2) if down else nn.ReLU()\n",
    "        )\n",
    "    \n",
    "    def forward(self, x):\n",
    "        return self.conv(x)\n",
    "\n",
    "class UNetGenerator(nn.Module):\n",
    "    def __init__(self, in_channels=1, out_channels=2):\n",
    "        super(UNetGenerator, self).__init__()\n",
    "        \n",
    "        self.down1 = UNetBlock(in_channels, 64, down=True, use_batchnorm=False)\n",
    "        self.down2 = UNetBlock(64, 128, down=True)\n",
    "        self.down3 = UNetBlock(128, 256, down=True)\n",
    "        self.down4 = UNetBlock(256, 512, down=True)\n",
    "        self.down5 = UNetBlock(512, 512, down=True)\n",
    "        self.down6 = UNetBlock(512, 512, down=True)\n",
    "        self.down7 = UNetBlock(512, 512, down=True)\n",
    "        self.down8 = UNetBlock(512, 512, down=True, use_batchnorm=False)\n",
    "        \n",
    "        self.up1 = UNetBlock(512, 512, down=False, use_dropout=True)\n",
    "        self.up2 = UNetBlock(1024, 512, down=False, use_dropout=True)\n",
    "        self.up3 = UNetBlock(1024, 512, down=False, use_dropout=True)\n",
    "        self.up4 = UNetBlock(1024, 512, down=False)\n",
    "        self.up5 = UNetBlock(1024, 256, down=False)\n",
    "        self.up6 = UNetBlock(512, 128, down=False)\n",
    "        self.up7 = UNetBlock(256, 64, down=False)\n",
    "        \n",
    "        self.final = nn.Sequential(\n",
    "            nn.ConvTranspose2d(128, out_channels, 4, 2, 1),\n",
    "            nn.Tanh()\n",
    "        )\n",
    "    \n",
    "    def forward(self, x):\n",
    "        d1 = self.down1(x)\n",
    "        d2 = self.down2(d1)\n",
    "        d3 = self.down3(d2)\n",
    "        d4 = self.down4(d3)\n",
    "        d5 = self.down5(d4)\n",
    "        d6 = self.down6(d5)\n",
    "        d7 = self.down7(d6)\n",
    "        d8 = self.down8(d7)\n",
    "        \n",
    "        u1 = self.up1(d8)\n",
    "        u2 = self.up2(torch.cat([u1, d7], 1))\n",
    "        u3 = self.up3(torch.cat([u2, d6], 1))\n",
    "        u4 = self.up4(torch.cat([u3, d5], 1))\n",
    "        u5 = self.up5(torch.cat([u4, d4], 1))\n",
    "        u6 = self.up6(torch.cat([u5, d3], 1))\n",
    "        u7 = self.up7(torch.cat([u6, d2], 1))\n",
    "        \n",
    "        return self.final(torch.cat([u7, d1], 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c9faf65",
   "metadata": {},
   "outputs": [],
   "source": [
    "class PatchGANDiscriminator(nn.Module):\n",
    "    def __init__(self, in_channels=3):\n",
    "        super(PatchGANDiscriminator, self).__init__()\n",
    "        \n",
    "        def discriminator_block(in_filters, out_filters, normalization=True):\n",
    "            layers = [nn.Conv2d(in_filters, out_filters, 4, stride=2, padding=1)]\n",
    "            if normalization:\n",
    "                layers.append(nn.BatchNorm2d(out_filters))\n",
    "            layers.append(nn.LeakyReLU(0.2, inplace=True))\n",
    "            return layers\n",
    "        \n",
    "        self.model = nn.Sequential(\n",
    "            *discriminator_block(in_channels, 64, normalization=False),\n",
    "            *discriminator_block(64, 128),\n",
    "            *discriminator_block(128, 256),\n",
    "            *discriminator_block(256, 512),\n",
    "            nn.ZeroPad2d((1, 0, 1, 0)),\n",
    "            nn.Conv2d(512, 1, 4, padding=1)\n",
    "        )\n",
    "    \n",
    "    def forward(self, img_L, img_ab):\n",
    "        img_input = torch.cat((img_L, img_ab), 1)\n",
    "        return self.model(img_input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f986047",
   "metadata": {},
   "outputs": [],
   "source": [
    "class PerceptualLoss(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(PerceptualLoss, self).__init__()\n",
    "        if vgg_weights is not None:\n",
    "            vgg = vgg16(weights=vgg_weights).features\n",
    "        else:\n",
    "            vgg = vgg16(pretrained=True).features\n",
    "        self.features = nn.Sequential(*list(vgg)[:16]).eval()\n",
    "        for param in self.features.parameters():\n",
    "            param.requires_grad = False\n",
    "        self.criterion = nn.L1Loss()\n",
    "    \n",
    "    def forward(self, pred, target):\n",
    "        pred_features = self.features(pred)\n",
    "        target_features = self.features(target)\n",
    "        return self.criterion(pred_features, target_features)\n",
    "\n",
    "class GANLoss(nn.Module):\n",
    "    def __init__(self, use_lsgan=True):\n",
    "        super(GANLoss, self).__init__()\n",
    "        self.loss = nn.MSELoss() if use_lsgan else nn.BCEWithLogitsLoss()\n",
    "    \n",
    "    def __call__(self, prediction, target_is_real):\n",
    "        target = torch.ones_like(prediction) if target_is_real else torch.zeros_like(prediction)\n",
    "        return self.loss(prediction, target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc600040",
   "metadata": {},
   "outputs": [],
   "source": [
    "generator = UNetGenerator().to(device)\n",
    "discriminator = PatchGANDiscriminator().to(device)\n",
    "\n",
    "criterion_L1 = nn.L1Loss().to(device)\n",
    "perceptual_loss = PerceptualLoss().to(device)\n",
    "gan_loss = GANLoss().to(device)\n",
    "\n",
    "optimizer_G = optim.Adam(generator.parameters(), lr=LEARNING_RATE, betas=(0.5, 0.999))\n",
    "optimizer_D = optim.Adam(discriminator.parameters(), lr=LEARNING_RATE, betas=(0.5, 0.999))\n",
    "\n",
    "train_dataset = ColorizeDataset(os.path.join(DATA_DIR, 'train_color'), IMAGE_SIZE, split='train')\n",
    "train_loader = DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True, num_workers=NUM_WORKERS)\n",
    "\n",
    "val_dataset = ColorizeDataset(os.path.join(DATA_DIR, 'val_color'), IMAGE_SIZE, split='val')\n",
    "val_loader = DataLoader(val_dataset, batch_size=BATCH_SIZE, shuffle=False, num_workers=NUM_WORKERS)\n",
    "\n",
    "print(f'Training samples: {len(train_dataset)}')\n",
    "print(f'Validation samples: {len(val_dataset)}')\n",
    "print(f'Generator parameters: {sum(p.numel() for p in generator.parameters()):,}')\n",
    "print(f'Discriminator parameters: {sum(p.numel() for p in discriminator.parameters()):,}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f1890db",
   "metadata": {},
   "outputs": [],
   "source": [
    "def validate_epoch(generator, val_loader, criterion_L1, perceptual_loss, device):\n",
    "    generator.eval()\n",
    "    total_loss = 0.0\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for L, ab in val_loader:\n",
    "            L, ab = L.to(device), ab.to(device)\n",
    "            fake_ab = generator(L)\n",
    "            \n",
    "            loss_l1 = criterion_L1(fake_ab, ab)\n",
    "            \n",
    "            fake_rgb = torch.cat([L.repeat(1, 3, 1, 1), fake_ab.repeat(1, 1, 1, 1)[:, :1, :, :]], dim=1)\n",
    "            real_rgb = torch.cat([L.repeat(1, 3, 1, 1), ab.repeat(1, 1, 1, 1)[:, :1, :, :]], dim=1)\n",
    "            loss_perceptual = perceptual_loss(fake_rgb, real_rgb)\n",
    "            \n",
    "            loss = loss_l1 * LAMBDA_L1 + loss_perceptual * LAMBDA_PERCEPTUAL\n",
    "            total_loss += loss.item()\n",
    "    \n",
    "    return total_loss / len(val_loader)\n",
    "\n",
    "def visualize_validation_samples(generator, val_loader, device, num_samples=8):\n",
    "    generator.eval()\n",
    "    with torch.no_grad():\n",
    "        L, ab = next(iter(val_loader))\n",
    "        L, ab = L[:num_samples].to(device), ab[:num_samples].to(device)\n",
    "        fake_ab = generator(L)\n",
    "        \n",
    "        def lab_to_rgb(L_tensor, ab_tensor):\n",
    "            L_np = (L_tensor + 1.0) * 50.0\n",
    "            ab_np = ab_tensor * 110.0\n",
    "            Lab = torch.cat([L_np, ab_np], dim=1).permute(0, 2, 3, 1).cpu().numpy()\n",
    "            rgb_imgs = []\n",
    "            for lab_img in Lab:\n",
    "                rgb_img = lab2rgb(lab_img)\n",
    "                rgb_imgs.append(rgb_img)\n",
    "            return np.array(rgb_imgs)\n",
    "        \n",
    "        pred_rgb = lab_to_rgb(L, fake_ab)\n",
    "        target_rgb = lab_to_rgb(L, ab)\n",
    "        grayscale = L.cpu().numpy()\n",
    "    \n",
    "    fig, axes = plt.subplots(3, num_samples, figsize=(20, 8))\n",
    "    for i in range(num_samples):\n",
    "        axes[0, i].imshow(grayscale[i, 0], cmap='gray')\n",
    "        axes[0, i].axis('off')\n",
    "        if i == 0:\n",
    "            axes[0, i].set_title('Grayscale', fontsize=10)\n",
    "        \n",
    "        axes[1, i].imshow(np.clip(pred_rgb[i], 0, 1))\n",
    "        axes[1, i].axis('off')\n",
    "        if i == 0:\n",
    "            axes[1, i].set_title('Colorized', fontsize=10)\n",
    "        \n",
    "        axes[2, i].imshow(np.clip(target_rgb[i], 0, 1))\n",
    "        axes[2, i].axis('off')\n",
    "        if i == 0:\n",
    "            axes[2, i].set_title('Ground Truth', fontsize=10)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0d82fe1",
   "metadata": {},
   "outputs": [],
   "source": [
    "history = {'epoch': [], 'train_loss': [], 'val_loss': [], 'gen_loss': [], 'disc_loss': []}\n",
    "best_val_loss = float('inf')\n",
    "\n",
    "for epoch in range(NUM_EPOCHS):\n",
    "    generator.train()\n",
    "    discriminator.train()\n",
    "    epoch_g_loss = 0.0\n",
    "    epoch_l1_loss = 0.0\n",
    "    epoch_perceptual_loss = 0.0\n",
    "    epoch_gan_loss = 0.0\n",
    "    epoch_d_loss = 0.0\n",
    "    \n",
    "    for i, (L, ab) in enumerate(train_loader):\n",
    "        L, ab = L.to(device), ab.to(device)\n",
    "        \n",
    "        optimizer_D.zero_grad()\n",
    "        \n",
    "        fake_ab = generator(L)\n",
    "        fake_pred = discriminator(L, fake_ab.detach())\n",
    "        real_pred = discriminator(L, ab)\n",
    "        \n",
    "        d_loss_fake = gan_loss(fake_pred, False)\n",
    "        d_loss_real = gan_loss(real_pred, True)\n",
    "        d_loss = (d_loss_fake + d_loss_real) * 0.5\n",
    "        \n",
    "        d_loss.backward()\n",
    "        optimizer_D.step()\n",
    "        \n",
    "        optimizer_G.zero_grad()\n",
    "        \n",
    "        fake_ab = generator(L)\n",
    "        fake_pred = discriminator(L, fake_ab)\n",
    "        \n",
    "        loss_l1 = criterion_L1(fake_ab, ab)\n",
    "        loss_gan_g = gan_loss(fake_pred, True)\n",
    "        \n",
    "        fake_rgb = torch.cat([L.repeat(1, 3, 1, 1), fake_ab.repeat(1, 1, 1, 1)[:, :1, :, :]], dim=1)\n",
    "        real_rgb = torch.cat([L.repeat(1, 3, 1, 1), ab.repeat(1, 1, 1, 1)[:, :1, :, :]], dim=1)\n",
    "        loss_perceptual = perceptual_loss(fake_rgb, real_rgb)\n",
    "        \n",
    "        g_loss = loss_gan_g + LAMBDA_L1 * loss_l1 + LAMBDA_PERCEPTUAL * loss_perceptual\n",
    "        \n",
    "        g_loss.backward()\n",
    "        optimizer_G.step()\n",
    "        \n",
    "        epoch_g_loss += g_loss.item()\n",
    "        epoch_l1_loss += loss_l1.item()\n",
    "        epoch_perceptual_loss += loss_perceptual.item()\n",
    "        epoch_gan_loss += loss_gan_g.item()\n",
    "        epoch_d_loss += d_loss.item()\n",
    "    \n",
    "    avg_train_loss = epoch_g_loss / len(train_loader)\n",
    "    avg_d_loss = epoch_d_loss / len(train_loader)\n",
    "    \n",
    "    val_loss = validate_epoch(generator, val_loader, criterion_L1, perceptual_loss, device)\n",
    "    \n",
    "    history['epoch'].append(epoch + 1)\n",
    "    history['train_loss'].append(avg_train_loss)\n",
    "    history['val_loss'].append(val_loss)\n",
    "    history['gen_loss'].append(avg_train_loss)\n",
    "    history['disc_loss'].append(avg_d_loss)\n",
    "    \n",
    "    print(f'Epoch [{epoch+1}/{NUM_EPOCHS}] Train Loss: {avg_train_loss:.4f}, Val Loss: {val_loss:.4f}, D_Loss: {avg_d_loss:.4f}')\n",
    "    \n",
    "    if val_loss < best_val_loss:\n",
    "        best_val_loss = val_loss\n",
    "        torch.save({\n",
    "            'epoch': epoch + 1,\n",
    "            'generator_state_dict': generator.state_dict(),\n",
    "            'discriminator_state_dict': discriminator.state_dict(),\n",
    "            'optimizer_G_state_dict': optimizer_G.state_dict(),\n",
    "            'optimizer_D_state_dict': optimizer_D.state_dict(),\n",
    "            'loss': val_loss,\n",
    "        }, os.path.join(MODEL_DIR, 'best_model.pt'))\n",
    "        print(f'Saved best model at epoch {epoch+1} with val_loss: {val_loss:.4f}')\n",
    "    \n",
    "    if (epoch + 1) % 10 == 0:\n",
    "        torch.save({\n",
    "            'epoch': epoch + 1,\n",
    "            'generator_state_dict': generator.state_dict(),\n",
    "            'discriminator_state_dict': discriminator.state_dict(),\n",
    "            'optimizer_G_state_dict': optimizer_G.state_dict(),\n",
    "            'optimizer_D_state_dict': optimizer_D.state_dict(),\n",
    "            'loss': avg_train_loss,\n",
    "        }, os.path.join(MODEL_DIR, f'checkpoint_epoch_{epoch+1}.pt'))\n",
    "        visualize_validation_samples(generator, val_loader, device, epoch + 1, RESULTS_DIR)\n",
    "    \n",
    "    history_df = pd.DataFrame(history)\n",
    "    history_df.to_csv(os.path.join(RESULTS_DIR, f'training_history_{MODEL_ID}.csv'), index=False)\n",
    "\n",
    "print('Training completed!')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e76facdf",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ColorimetricEvaluator:\n",
    "    def __init__(self, device):\n",
    "        self.device = device\n",
    "        self.lpips_fn = lpips.LPIPS(net='alex').to(device)\n",
    "    \n",
    "    def lab_to_rgb(self, L, ab):\n",
    "        L = (L + 1.0) * 50.0\n",
    "        ab = ab * 110.0\n",
    "        Lab = torch.cat([L, ab], dim=1).permute(0, 2, 3, 1).cpu().numpy()\n",
    "        rgb_imgs = []\n",
    "        for lab_img in Lab:\n",
    "            rgb_img = lab2rgb(lab_img)\n",
    "            rgb_imgs.append(rgb_img)\n",
    "        return np.array(rgb_imgs)\n",
    "    \n",
    "    def calculate_psnr(self, pred, target):\n",
    "        pred = np.clip(pred, 0, 1)\n",
    "        target = np.clip(target, 0, 1)\n",
    "        psnr_values = [psnr(t, p, data_range=1.0) for p, t in zip(pred, target)]\n",
    "        return np.mean(psnr_values)\n",
    "    \n",
    "    def calculate_ssim(self, pred, target):\n",
    "        pred = np.clip(pred, 0, 1)\n",
    "        target = np.clip(target, 0, 1)\n",
    "        ssim_values = [ssim(t, p, data_range=1.0, channel_axis=2) for p, t in zip(pred, target)]\n",
    "        return np.mean(ssim_values)\n",
    "    \n",
    "    def calculate_ciede2000(self, pred, target):\n",
    "        pred = np.clip(pred * 255, 0, 255).astype(np.uint8)\n",
    "        target = np.clip(target * 255, 0, 255).astype(np.uint8)\n",
    "        \n",
    "        delta_e_values = []\n",
    "        for p, t in zip(pred, target):\n",
    "            p_lab = rgb2lab(p / 255.0)\n",
    "            t_lab = rgb2lab(t / 255.0)\n",
    "            \n",
    "            p_mean = np.mean(p_lab, axis=(0, 1))\n",
    "            t_mean = np.mean(t_lab, axis=(0, 1))\n",
    "            \n",
    "            p_color = LabColor(p_mean[0], p_mean[1], p_mean[2])\n",
    "            t_color = LabColor(t_mean[0], t_mean[1], t_mean[2])\n",
    "            \n",
    "            delta_e = delta_e_cie2000(p_color, t_color)\n",
    "            delta_e_values.append(delta_e)\n",
    "        \n",
    "        return np.mean(delta_e_values)\n",
    "    \n",
    "    def calculate_lpips(self, pred, target):\n",
    "        pred_tensor = torch.from_numpy(pred).permute(0, 3, 1, 2).float().to(self.device) * 2 - 1\n",
    "        target_tensor = torch.from_numpy(target).permute(0, 3, 1, 2).float().to(self.device) * 2 - 1\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            lpips_values = self.lpips_fn(pred_tensor, target_tensor)\n",
    "        \n",
    "        return lpips_values.mean().item()\n",
    "    \n",
    "    def evaluate(self, generator, dataloader):\n",
    "        generator.eval()\n",
    "        all_pred_rgb = []\n",
    "        all_target_rgb = []\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            for L, ab in dataloader:\n",
    "                L, ab = L.to(self.device), ab.to(self.device)\n",
    "                fake_ab = generator(L)\n",
    "                \n",
    "                pred_rgb = self.lab_to_rgb(L, fake_ab)\n",
    "                target_rgb = self.lab_to_rgb(L, ab)\n",
    "                \n",
    "                all_pred_rgb.append(pred_rgb)\n",
    "                all_target_rgb.append(target_rgb)\n",
    "        \n",
    "        all_pred_rgb = np.concatenate(all_pred_rgb, axis=0)\n",
    "        all_target_rgb = np.concatenate(all_target_rgb, axis=0)\n",
    "        \n",
    "        metrics = {\n",
    "            'PSNR': self.calculate_psnr(all_pred_rgb, all_target_rgb),\n",
    "            'SSIM': self.calculate_ssim(all_pred_rgb, all_target_rgb),\n",
    "            'CIEDE2000': self.calculate_ciede2000(all_pred_rgb, all_target_rgb),\n",
    "            'LPIPS': self.calculate_lpips(all_pred_rgb, all_target_rgb)\n",
    "        }\n",
    "        \n",
    "        return metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1c33349",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(10, 6))\n",
    "ax.plot(history['epoch'], history['train_loss'], label='Train Loss', marker='o')\n",
    "ax.plot(history['epoch'], history['val_loss'], label='Val Loss', marker='s')\n",
    "ax.set_xlabel('Epoch')\n",
    "ax.set_ylabel('Loss')\n",
    "ax.set_title('Training and Validation Loss')\n",
    "ax.legend()\n",
    "ax.grid(True)\n",
    "plt.tight_layout()\n",
    "plt.savefig(os.path.join(RESULTS_DIR, f'train_val_loss_{MODEL_ID}.png'), dpi=300, bbox_inches='tight')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8965260",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_dataset = ColorizeDataset(os.path.join(DATA_DIR, 'test_color'), IMAGE_SIZE)\n",
    "test_loader = DataLoader(test_dataset, batch_size=BATCH_SIZE, shuffle=False, num_workers=NUM_WORKERS)\n",
    "\n",
    "evaluator = ColorimetricEvaluator(device)\n",
    "\n",
    "checkpoint = torch.load(os.path.join(MODEL_DIR, 'best_model.pt'), map_location=device)\n",
    "generator.load_state_dict(checkpoint['generator_state_dict'])\n",
    "\n",
    "print('Evaluating model...')\n",
    "metrics = evaluator.evaluate(generator, test_loader)\n",
    "\n",
    "print('\\nEvaluation Results:')\n",
    "for metric, value in metrics.items():\n",
    "    print(f'{metric}: {value:.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6f38490",
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics_df = pd.DataFrame([metrics])\n",
    "metrics_df['model'] = MODEL_ID\n",
    "metrics_df.to_csv(os.path.join(RESULTS_DIR, f'metrics_{MODEL_ID}.csv'), index=False)\n",
    "print(f'Metrics saved to {RESULTS_DIR}/metrics_{MODEL_ID}.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31017010",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(2, 3, figsize=(18, 10))\n",
    "\n",
    "axes[0, 0].plot(history['epoch'], history['g_loss'])\n",
    "axes[0, 0].set_title('Generator Loss')\n",
    "axes[0, 0].set_xlabel('Epoch')\n",
    "axes[0, 0].set_ylabel('Loss')\n",
    "axes[0, 0].grid(True)\n",
    "\n",
    "axes[0, 1].plot(history['epoch'], history['d_loss'])\n",
    "axes[0, 1].set_title('Discriminator Loss')\n",
    "axes[0, 1].set_xlabel('Epoch')\n",
    "axes[0, 1].set_ylabel('Loss')\n",
    "axes[0, 1].grid(True)\n",
    "\n",
    "axes[0, 2].plot(history['epoch'], history['loss_gan'], label='GAN Loss')\n",
    "axes[0, 2].set_title('GAN Loss')\n",
    "axes[0, 2].set_xlabel('Epoch')\n",
    "axes[0, 2].set_ylabel('Loss')\n",
    "axes[0, 2].legend()\n",
    "axes[0, 2].grid(True)\n",
    "\n",
    "axes[1, 0].plot(history['epoch'], history['loss_l1'], label='L1 Loss')\n",
    "axes[1, 0].set_title('L1 Loss (λ₁ = 50.0)')\n",
    "axes[1, 0].set_xlabel('Epoch')\n",
    "axes[1, 0].set_ylabel('Loss')\n",
    "axes[1, 0].legend()\n",
    "axes[1, 0].grid(True)\n",
    "\n",
    "axes[1, 1].plot(history['epoch'], history['loss_perceptual'], label='Perceptual Loss')\n",
    "axes[1, 1].set_title('Perceptual Loss')\n",
    "axes[1, 1].set_xlabel('Epoch')\n",
    "axes[1, 1].set_ylabel('Loss')\n",
    "axes[1, 1].legend()\n",
    "axes[1, 1].grid(True)\n",
    "\n",
    "axes[1, 2].plot(history['epoch'], history['loss_l1'], label='L1', alpha=0.7)\n",
    "axes[1, 2].plot(history['epoch'], history['loss_perceptual'], label='Perceptual', alpha=0.7)\n",
    "axes[1, 2].plot(history['epoch'], history['loss_gan'], label='GAN', alpha=0.7)\n",
    "axes[1, 2].set_title('All Loss Components')\n",
    "axes[1, 2].set_xlabel('Epoch')\n",
    "axes[1, 2].set_ylabel('Loss')\n",
    "axes[1, 2].legend()\n",
    "axes[1, 2].grid(True)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig(os.path.join(RESULTS_DIR, f'training_history_{MODEL_ID}.png'), dpi=300, bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "print(f'Training history plot saved to {RESULTS_DIR}/training_history_{MODEL_ID}.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84fff424",
   "metadata": {},
   "outputs": [],
   "source": [
    "generator.eval()\n",
    "with torch.no_grad():\n",
    "    sample_L, sample_ab = next(iter(test_loader))\n",
    "    sample_L, sample_ab = sample_L[:8].to(device), sample_ab[:8].to(device)\n",
    "    fake_ab = generator(sample_L)\n",
    "    \n",
    "    evaluator_viz = ColorimetricEvaluator(device)\n",
    "    pred_rgb = evaluator_viz.lab_to_rgb(sample_L, fake_ab)\n",
    "    target_rgb = evaluator_viz.lab_to_rgb(sample_L, sample_ab)\n",
    "    grayscale = sample_L.cpu().numpy()\n",
    "\n",
    "fig, axes = plt.subplots(3, 8, figsize=(20, 8))\n",
    "for i in range(8):\n",
    "    axes[0, i].imshow(grayscale[i, 0], cmap='gray')\n",
    "    axes[0, i].axis('off')\n",
    "    if i == 0:\n",
    "        axes[0, i].set_title('Grayscale', fontsize=10)\n",
    "    \n",
    "    axes[1, i].imshow(np.clip(pred_rgb[i], 0, 1))\n",
    "    axes[1, i].axis('off')\n",
    "    if i == 0:\n",
    "        axes[1, i].set_title('Colorized', fontsize=10)\n",
    "    \n",
    "    axes[2, i].imshow(np.clip(target_rgb[i], 0, 1))\n",
    "    axes[2, i].axis('off')\n",
    "    if i == 0:\n",
    "        axes[2, i].set_title('Ground Truth', fontsize=10)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig(os.path.join(RESULTS_DIR, f'colorization_results_{MODEL_ID}.png'), dpi=300, bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "print(f'Colorization results saved to {RESULTS_DIR}/colorization_results_{MODEL_ID}.png')"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
