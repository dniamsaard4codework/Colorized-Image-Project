{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37aff758",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torchvision.transforms as transforms\n",
    "from torchvision.models import vgg16\n",
    "try:\n",
    "    from torchvision.models import VGG16_Weights\n",
    "    vgg_weights = VGG16_Weights.IMAGENET1K_V1\n",
    "except ImportError:\n",
    "    vgg_weights = None\n",
    "\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "import os\n",
    "from skimage.color import rgb2lab, lab2rgb\n",
    "from skimage.metrics import peak_signal_noise_ratio as psnr\n",
    "from skimage.metrics import structural_similarity as ssim\n",
    "import lpips\n",
    "from colormath.color_objects import LabColor, sRGBColor\n",
    "from colormath.color_conversions import convert_color\n",
    "from colormath.color_diff import delta_e_cie2000\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import warnings\n",
    "\n",
    "# Suppress warnings for LAB conversion edge cases\n",
    "warnings.filterwarnings('ignore', category=RuntimeWarning)\n",
    "\n",
    "# Fix for numpy.asscalar removal in numpy 1.23+\n",
    "if not hasattr(np, 'asscalar'):\n",
    "    np.asscalar = lambda x: x.item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33bdad92",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configuration\n",
    "MODEL_ID = 'H1'\n",
    "USE_GAN = True\n",
    "USE_L1 = True\n",
    "USE_PERCEPTUAL = False\n",
    "LAMBDA_L1 = 100.0\n",
    "\n",
    "BATCH_SIZE = 64\n",
    "NUM_EPOCHS = 50\n",
    "LEARNING_RATE = 2e-4\n",
    "IMAGE_SIZE = 256\n",
    "NUM_WORKERS = 4\n",
    "\n",
    "DATA_DIR = '../data/colorize_dataset/data'\n",
    "MODEL_DIR = f'../models/{MODEL_ID}'\n",
    "RESULTS_DIR = '../results'\n",
    "\n",
    "os.makedirs(MODEL_DIR, exist_ok=True)\n",
    "os.makedirs(RESULTS_DIR, exist_ok=True)\n",
    "\n",
    "# Device configuration\n",
    "if torch.cuda.is_available():\n",
    "    device = torch.device('cuda')\n",
    "elif torch.backends.mps.is_available():\n",
    "    device = torch.device('mps')\n",
    "else:\n",
    "    device = torch.device('cpu')\n",
    "print(f'Using device: {device}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f467c94",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ColorizeDataset(Dataset):\n",
    "    def __init__(self, color_dir, size=256, split='train'):\n",
    "        self.color_dir = color_dir\n",
    "        self.size = size\n",
    "        self.split = split\n",
    "        self.images = [f for f in os.listdir(color_dir) if f.endswith(('.jpg', '.jpeg', '.png'))]\n",
    "        \n",
    "        if split == 'train':\n",
    "            self.transform = transforms.Compose([\n",
    "                transforms.Resize((size, size)),\n",
    "                transforms.RandomHorizontalFlip(0.5),\n",
    "                transforms.RandomRotation(15),\n",
    "                transforms.ColorJitter(brightness=0.2, contrast=0.2, saturation=0.2, hue=0.1),\n",
    "                transforms.RandomAffine(degrees=0, translate=(0.1, 0.1)),\n",
    "                transforms.ToTensor()\n",
    "            ])\n",
    "        else:\n",
    "            self.transform = transforms.Compose([\n",
    "                transforms.Resize((size, size)),\n",
    "                transforms.ToTensor()\n",
    "            ])\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.images)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        img_path = os.path.join(self.color_dir, self.images[idx])\n",
    "        img = Image.open(img_path).convert('RGB')\n",
    "        img = self.transform(img)\n",
    "        \n",
    "        # Convert to LAB\n",
    "        img_np = img.permute(1, 2, 0).numpy()\n",
    "        lab = rgb2lab(img_np)\n",
    "        \n",
    "        # Normalize\n",
    "        L = lab[:, :, 0] / 50.0 - 1.0  # [-1, 1]\n",
    "        ab = lab[:, :, 1:] / 110.0      # [-1, 1]\n",
    "        \n",
    "        L = torch.from_numpy(L).float().unsqueeze(0)\n",
    "        ab = torch.from_numpy(ab).float().permute(2, 0, 1)\n",
    "        \n",
    "        return L, ab\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a1411ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ResidualBlock(nn.Module):\n",
    "    \"\"\"Residual block for ResNet generator\"\"\"\n",
    "    def __init__(self, channels):\n",
    "        super(ResidualBlock, self).__init__()\n",
    "        self.conv_block = nn.Sequential(\n",
    "            nn.ReflectionPad2d(1),\n",
    "            nn.Conv2d(channels, channels, 3),\n",
    "            nn.BatchNorm2d(channels),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.ReflectionPad2d(1),\n",
    "            nn.Conv2d(channels, channels, 3),\n",
    "            nn.BatchNorm2d(channels)\n",
    "        )\n",
    "    \n",
    "    def forward(self, x):\n",
    "        return x + self.conv_block(x)\n",
    "\n",
    "class ResNetGenerator(nn.Module):\n",
    "    \"\"\"ResNet-based generator with 9 residual blocks\"\"\"\n",
    "    def __init__(self, in_channels=1, out_channels=2, num_residual_blocks=9):\n",
    "        super(ResNetGenerator, self).__init__()\n",
    "        \n",
    "        # Initial convolution\n",
    "        model = [\n",
    "            nn.ReflectionPad2d(3),\n",
    "            nn.Conv2d(in_channels, 64, 7),\n",
    "            nn.BatchNorm2d(64),\n",
    "            nn.ReLU(inplace=True)\n",
    "        ]\n",
    "        \n",
    "        # Downsampling\n",
    "        in_features = 64\n",
    "        out_features = in_features * 2\n",
    "        for _ in range(2):\n",
    "            model += [\n",
    "                nn.Conv2d(in_features, out_features, 3, stride=2, padding=1),\n",
    "                nn.BatchNorm2d(out_features),\n",
    "                nn.ReLU(inplace=True)\n",
    "            ]\n",
    "            in_features = out_features\n",
    "            out_features = in_features * 2\n",
    "        \n",
    "        # Residual blocks\n",
    "        for _ in range(num_residual_blocks):\n",
    "            model += [ResidualBlock(in_features)]\n",
    "        \n",
    "        # Upsampling\n",
    "        out_features = in_features // 2\n",
    "        for _ in range(2):\n",
    "            model += [\n",
    "                nn.ConvTranspose2d(in_features, out_features, 3, stride=2, padding=1, output_padding=1),\n",
    "                nn.BatchNorm2d(out_features),\n",
    "                nn.ReLU(inplace=True)\n",
    "            ]\n",
    "            in_features = out_features\n",
    "            out_features = in_features // 2\n",
    "        \n",
    "        # Output layer\n",
    "        model += [\n",
    "            nn.ReflectionPad2d(3),\n",
    "            nn.Conv2d(64, out_channels, 7),\n",
    "            nn.Tanh()\n",
    "        ]\n",
    "        \n",
    "        self.model = nn.Sequential(*model)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        return self.model(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ba4b358",
   "metadata": {},
   "outputs": [],
   "source": [
    "class PatchGANDiscriminator(nn.Module):\n",
    "    def __init__(self, in_channels=3):\n",
    "        super(PatchGANDiscriminator, self).__init__()\n",
    "        \n",
    "        def discriminator_block(in_filters, out_filters, normalization=True):\n",
    "            layers = [nn.Conv2d(in_filters, out_filters, 4, stride=2, padding=1)]\n",
    "            if normalization:\n",
    "                layers.append(nn.BatchNorm2d(out_filters))\n",
    "            layers.append(nn.LeakyReLU(0.2, inplace=True))\n",
    "            return layers\n",
    "        \n",
    "        self.model = nn.Sequential(\n",
    "            *discriminator_block(in_channels, 64, normalization=False),\n",
    "            *discriminator_block(64, 128),\n",
    "            *discriminator_block(128, 256),\n",
    "            *discriminator_block(256, 512),\n",
    "            nn.ZeroPad2d((1, 0, 1, 0)),\n",
    "            nn.Conv2d(512, 1, 4, padding=1)\n",
    "        )\n",
    "    \n",
    "    def forward(self, img_L, img_ab):\n",
    "        img_input = torch.cat((img_L, img_ab), 1)\n",
    "        return self.model(img_input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ad6e071",
   "metadata": {},
   "outputs": [],
   "source": [
    "class GANLoss(nn.Module):\n",
    "    def __init__(self, use_lsgan=True):\n",
    "        super(GANLoss, self).__init__()\n",
    "        self.loss = nn.MSELoss() if use_lsgan else nn.BCEWithLogitsLoss()\n",
    "    \n",
    "    def __call__(self, prediction, target_is_real):\n",
    "        target = torch.ones_like(prediction) if target_is_real else torch.zeros_like(prediction)\n",
    "        return self.loss(prediction, target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66e0de65",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize models\n",
    "generator = ResNetGenerator().to(device)\n",
    "discriminator = PatchGANDiscriminator().to(device)\n",
    "\n",
    "# Loss functions\n",
    "criterion_L1 = nn.L1Loss().to(device)\n",
    "gan_loss = GANLoss().to(device)\n",
    "\n",
    "# Optimizers\n",
    "optimizer_G = optim.Adam(generator.parameters(), lr=LEARNING_RATE, betas=(0.5, 0.999))\n",
    "optimizer_D = optim.Adam(discriminator.parameters(), lr=LEARNING_RATE, betas=(0.5, 0.999))\n",
    "\n",
    "# Data loaders\n",
    "train_dataset = ColorizeDataset(os.path.join(DATA_DIR, 'train_color'), IMAGE_SIZE, split='train')\n",
    "train_loader = DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True, num_workers=NUM_WORKERS)\n",
    "\n",
    "val_dataset = ColorizeDataset(os.path.join(DATA_DIR, 'val_color'), IMAGE_SIZE, split='val')\n",
    "val_loader = DataLoader(val_dataset, batch_size=BATCH_SIZE, shuffle=False, num_workers=NUM_WORKERS)\n",
    "\n",
    "print(f'Training samples: {len(train_dataset)}')\n",
    "print(f'Validation samples: {len(val_dataset)}')\n",
    "print(f'Generator parameters: {sum(p.numel() for p in generator.parameters()):,}')\n",
    "print(f'Discriminator parameters: {sum(p.numel() for p in discriminator.parameters()):,}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc4b5fb1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def validate_epoch(generator, val_loader, device):\n",
    "    \"\"\"Validate generator on validation set\"\"\"\n",
    "    generator.eval()\n",
    "    total_val_loss = 0.0\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for L, ab in val_loader:\n",
    "            L, ab = L.to(device), ab.to(device)\n",
    "            fake_ab = generator(L)\n",
    "            \n",
    "            # Only L1 loss for validation (no GAN, no perceptual)\n",
    "            l1_loss = criterion_L1(fake_ab, ab)\n",
    "            val_loss = l1_loss * LAMBDA_L1\n",
    "            \n",
    "            total_val_loss += val_loss.item()\n",
    "    \n",
    "    avg_val_loss = total_val_loss / len(val_loader)\n",
    "    return avg_val_loss\n",
    "\n",
    "def visualize_validation_samples(generator, val_loader, device, epoch, results_dir):\n",
    "    \"\"\"Visualize validation samples\"\"\"\n",
    "    generator.eval()\n",
    "    with torch.no_grad():\n",
    "        sample_L, sample_ab = next(iter(val_loader))\n",
    "        sample_L, sample_ab = sample_L[:8].to(device), sample_ab[:8].to(device)\n",
    "        fake_ab = generator(sample_L)\n",
    "        \n",
    "        # Convert to RGB\n",
    "        def lab_to_rgb_viz(L, ab):\n",
    "            L = (L + 1.0) * 50.0\n",
    "            ab = ab * 110.0\n",
    "            Lab = torch.cat([L, ab], dim=1).permute(0, 2, 3, 1).cpu().numpy()\n",
    "            rgb_imgs = []\n",
    "            for lab_img in Lab:\n",
    "                rgb_img = lab2rgb(lab_img)\n",
    "                rgb_imgs.append(rgb_img)\n",
    "            return np.array(rgb_imgs)\n",
    "        \n",
    "        pred_rgb = lab_to_rgb_viz(sample_L, fake_ab)\n",
    "        target_rgb = lab_to_rgb_viz(sample_L, sample_ab)\n",
    "        grayscale = sample_L.cpu().numpy()\n",
    "    \n",
    "    fig, axes = plt.subplots(3, 8, figsize=(20, 8))\n",
    "    for i in range(8):\n",
    "        axes[0, i].imshow(grayscale[i, 0], cmap='gray')\n",
    "        axes[0, i].axis('off')\n",
    "        if i == 0:\n",
    "            axes[0, i].set_title('Grayscale', fontsize=10)\n",
    "        \n",
    "        axes[1, i].imshow(np.clip(pred_rgb[i], 0, 1))\n",
    "        axes[1, i].axis('off')\n",
    "        if i == 0:\n",
    "            axes[1, i].set_title('Colorized', fontsize=10)\n",
    "        \n",
    "        axes[2, i].imshow(np.clip(target_rgb[i], 0, 1))\n",
    "        axes[2, i].axis('off')\n",
    "        if i == 0:\n",
    "            axes[2, i].set_title('Ground Truth', fontsize=10)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.savefig(os.path.join(results_dir, f'val_samples_epoch_{epoch}.png'), dpi=150, bbox_inches='tight')\n",
    "    plt.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "350b955c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training loop\n",
    "history = {'epoch': [], 'train_loss': [], 'val_loss': [], 'gen_loss': [], 'disc_loss': []}\n",
    "best_val_loss = float('inf')\n",
    "\n",
    "for epoch in range(NUM_EPOCHS):\n",
    "    generator.train()\n",
    "    discriminator.train()\n",
    "    epoch_g_loss = 0.0\n",
    "    epoch_l1_loss = 0.0\n",
    "    epoch_gan_loss = 0.0\n",
    "    epoch_d_loss = 0.0\n",
    "    \n",
    "    for i, (L, ab) in enumerate(train_loader):\n",
    "        L, ab = L.to(device), ab.to(device)\n",
    "        \n",
    "        # Train Discriminator\n",
    "        optimizer_D.zero_grad()\n",
    "        \n",
    "        fake_ab = generator(L)\n",
    "        fake_pred = discriminator(L, fake_ab.detach())\n",
    "        real_pred = discriminator(L, ab)\n",
    "        \n",
    "        d_loss_fake = gan_loss(fake_pred, False)\n",
    "        d_loss_real = gan_loss(real_pred, True)\n",
    "        d_loss = (d_loss_fake + d_loss_real) * 0.5\n",
    "        \n",
    "        d_loss.backward()\n",
    "        optimizer_D.step()\n",
    "        \n",
    "        # Train Generator\n",
    "        optimizer_G.zero_grad()\n",
    "        \n",
    "        fake_ab = generator(L)\n",
    "        fake_pred = discriminator(L, fake_ab)\n",
    "        \n",
    "        # L1 loss\n",
    "        loss_l1 = criterion_L1(fake_ab, ab)\n",
    "        \n",
    "        # GAN loss\n",
    "        loss_gan_g = gan_loss(fake_pred, True)\n",
    "        \n",
    "        # Total generator loss (GAN + L1 only, no Perceptual)\n",
    "        g_loss = loss_gan_g + LAMBDA_L1 * loss_l1\n",
    "        \n",
    "        g_loss.backward()\n",
    "        optimizer_G.step()\n",
    "        \n",
    "        epoch_g_loss += g_loss.item()\n",
    "        epoch_l1_loss += loss_l1.item()\n",
    "        epoch_gan_loss += loss_gan_g.item()\n",
    "        epoch_d_loss += d_loss.item()\n",
    "    \n",
    "    # Average losses\n",
    "    avg_g_loss = epoch_g_loss / len(train_loader)\n",
    "    avg_l1_loss = epoch_l1_loss / len(train_loader)\n",
    "    avg_gan_loss = epoch_gan_loss / len(train_loader)\n",
    "    avg_d_loss = epoch_d_loss / len(train_loader)\n",
    "    \n",
    "    # Validation\n",
    "    avg_val_loss = validate_epoch(generator, val_loader, device)\n",
    "    \n",
    "    # Update history\n",
    "    history['epoch'].append(epoch + 1)\n",
    "    history['train_loss'].append(avg_g_loss)\n",
    "    history['val_loss'].append(avg_val_loss)\n",
    "    history['gen_loss'].append(avg_g_loss)\n",
    "    history['disc_loss'].append(avg_d_loss)\n",
    "    \n",
    "    print(f'Epoch [{epoch+1}/{NUM_EPOCHS}] Train_Loss: {avg_g_loss:.4f} Val_Loss: {avg_val_loss:.4f} (GAN: {avg_gan_loss:.4f}, L1: {avg_l1_loss:.4f}) D_Loss: {avg_d_loss:.4f}')\n",
    "    \n",
    "    # Save best model based on validation loss\n",
    "    if avg_val_loss < best_val_loss:\n",
    "        best_val_loss = avg_val_loss\n",
    "        torch.save({\n",
    "            'epoch': epoch + 1,\n",
    "            'generator_state_dict': generator.state_dict(),\n",
    "            'discriminator_state_dict': discriminator.state_dict(),\n",
    "            'optimizer_G_state_dict': optimizer_G.state_dict(),\n",
    "            'optimizer_D_state_dict': optimizer_D.state_dict(),\n",
    "            'loss': avg_val_loss,\n",
    "        }, os.path.join(MODEL_DIR, 'best_model.pt'))\n",
    "        print(f'Saved best model at epoch {epoch+1} with val_loss {avg_val_loss:.4f}')\n",
    "    \n",
    "    # Visualize validation samples every 10 epochs\n",
    "    if (epoch + 1) % 10 == 0:\n",
    "        visualize_validation_samples(generator, val_loader, device, epoch + 1, RESULTS_DIR)\n",
    "        torch.save({\n",
    "            'epoch': epoch + 1,\n",
    "            'generator_state_dict': generator.state_dict(),\n",
    "            'discriminator_state_dict': discriminator.state_dict(),\n",
    "            'optimizer_G_state_dict': optimizer_G.state_dict(),\n",
    "            'optimizer_D_state_dict': optimizer_D.state_dict(),\n",
    "            'loss': avg_val_loss,\n",
    "        }, os.path.join(MODEL_DIR, f'checkpoint_epoch_{epoch+1}.pt'))\n",
    "    \n",
    "    # Save training history after each epoch\n",
    "    history_df = pd.DataFrame(history)\n",
    "    history_df.to_csv(os.path.join(RESULTS_DIR, f'training_history_{MODEL_ID}.csv'), index=False)\n",
    "\n",
    "print('Training completed!')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a633c67",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ColorimetricEvaluator:\n",
    "    def __init__(self, device):\n",
    "        self.device = device\n",
    "        self.lpips_fn = lpips.LPIPS(net='alex').to(device)\n",
    "    \n",
    "    def lab_to_rgb(self, L, ab):\n",
    "        L = (L + 1.0) * 50.0\n",
    "        ab = ab * 110.0\n",
    "        Lab = torch.cat([L, ab], dim=1).permute(0, 2, 3, 1).cpu().numpy()\n",
    "        rgb_imgs = []\n",
    "        for lab_img in Lab:\n",
    "            rgb_img = lab2rgb(lab_img)\n",
    "            rgb_imgs.append(rgb_img)\n",
    "        return np.array(rgb_imgs)\n",
    "    \n",
    "    def calculate_psnr(self, pred, target):\n",
    "        pred = np.clip(pred, 0, 1)\n",
    "        target = np.clip(target, 0, 1)\n",
    "        psnr_values = [psnr(t, p, data_range=1.0) for p, t in zip(pred, target)]\n",
    "        return np.mean(psnr_values)\n",
    "    \n",
    "    def calculate_ssim(self, pred, target):\n",
    "        pred = np.clip(pred, 0, 1)\n",
    "        target = np.clip(target, 0, 1)\n",
    "        ssim_values = [ssim(t, p, data_range=1.0, channel_axis=2) for p, t in zip(pred, target)]\n",
    "        return np.mean(ssim_values)\n",
    "    \n",
    "    def calculate_ciede2000(self, pred, target):\n",
    "        pred = np.clip(pred * 255, 0, 255).astype(np.uint8)\n",
    "        target = np.clip(target * 255, 0, 255).astype(np.uint8)\n",
    "        \n",
    "        delta_e_values = []\n",
    "        for p, t in zip(pred, target):\n",
    "            p_lab = rgb2lab(p / 255.0)\n",
    "            t_lab = rgb2lab(t / 255.0)\n",
    "            \n",
    "            p_mean = np.mean(p_lab, axis=(0, 1))\n",
    "            t_mean = np.mean(t_lab, axis=(0, 1))\n",
    "            \n",
    "            p_color = LabColor(p_mean[0], p_mean[1], p_mean[2])\n",
    "            t_color = LabColor(t_mean[0], t_mean[1], t_mean[2])\n",
    "            \n",
    "            delta_e = delta_e_cie2000(p_color, t_color)\n",
    "            delta_e_values.append(delta_e)\n",
    "        \n",
    "        return np.mean(delta_e_values)\n",
    "    \n",
    "    def calculate_lpips(self, pred, target):\n",
    "        pred_tensor = torch.from_numpy(pred).permute(0, 3, 1, 2).float().to(self.device) * 2 - 1\n",
    "        target_tensor = torch.from_numpy(target).permute(0, 3, 1, 2).float().to(self.device) * 2 - 1\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            lpips_values = self.lpips_fn(pred_tensor, target_tensor)\n",
    "        \n",
    "        return lpips_values.mean().item()\n",
    "    \n",
    "    def evaluate(self, generator, dataloader):\n",
    "        generator.eval()\n",
    "        all_pred_rgb = []\n",
    "        all_target_rgb = []\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            for L, ab in dataloader:\n",
    "                L, ab = L.to(self.device), ab.to(self.device)\n",
    "                fake_ab = generator(L)\n",
    "                \n",
    "                pred_rgb = self.lab_to_rgb(L, fake_ab)\n",
    "                target_rgb = self.lab_to_rgb(L, ab)\n",
    "                \n",
    "                all_pred_rgb.append(pred_rgb)\n",
    "                all_target_rgb.append(target_rgb)\n",
    "        \n",
    "        all_pred_rgb = np.concatenate(all_pred_rgb, axis=0)\n",
    "        all_target_rgb = np.concatenate(all_target_rgb, axis=0)\n",
    "        \n",
    "        metrics = {\n",
    "            'PSNR': self.calculate_psnr(all_pred_rgb, all_target_rgb),\n",
    "            'SSIM': self.calculate_ssim(all_pred_rgb, all_target_rgb),\n",
    "            'CIEDE2000': self.calculate_ciede2000(all_pred_rgb, all_target_rgb),\n",
    "            'LPIPS': self.calculate_lpips(all_pred_rgb, all_target_rgb)\n",
    "        }\n",
    "        \n",
    "        return metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "841b45b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluation\n",
    "test_dataset = ColorizeDataset(os.path.join(DATA_DIR, 'test_color'), IMAGE_SIZE)\n",
    "test_loader = DataLoader(test_dataset, batch_size=BATCH_SIZE, shuffle=False, num_workers=NUM_WORKERS)\n",
    "\n",
    "evaluator = ColorimetricEvaluator(device)\n",
    "\n",
    "# Load best model\n",
    "checkpoint = torch.load(os.path.join(MODEL_DIR, 'best_model.pt'), map_location=device)\n",
    "generator.load_state_dict(checkpoint['generator_state_dict'])\n",
    "\n",
    "print('Evaluating model...')\n",
    "metrics = evaluator.evaluate(generator, test_loader)\n",
    "\n",
    "print('\\nEvaluation Results:')\n",
    "for metric, value in metrics.items():\n",
    "    print(f'{metric}: {value:.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "657c6d7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save metrics\n",
    "metrics_df = pd.DataFrame([metrics])\n",
    "metrics_df['model'] = MODEL_ID\n",
    "metrics_df['Best_Val_Loss'] = best_val_loss\n",
    "metrics_df.to_csv(os.path.join(RESULTS_DIR, f'metrics_{MODEL_ID}.csv'), index=False)\n",
    "print(f'Metrics saved to {RESULTS_DIR}/metrics_{MODEL_ID}.csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68f67f9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot training history\n",
    "fig, axes = plt.subplots(1, 2, figsize=(15, 5))\n",
    "\n",
    "# Generator loss (train and val)\n",
    "axes[0].plot(history['epoch'], history['train_loss'], label='Train Loss')\n",
    "axes[0].plot(history['epoch'], history['val_loss'], label='Val Loss')\n",
    "axes[0].set_title('Generator Loss (Train vs Val)')\n",
    "axes[0].set_xlabel('Epoch')\n",
    "axes[0].set_ylabel('Loss')\n",
    "axes[0].legend()\n",
    "axes[0].grid(True)\n",
    "\n",
    "# Discriminator loss\n",
    "axes[1].plot(history['epoch'], history['disc_loss'], label='Discriminator Loss')\n",
    "axes[1].set_title('Discriminator Loss')\n",
    "axes[1].set_xlabel('Epoch')\n",
    "axes[1].set_ylabel('Loss')\n",
    "axes[1].legend()\n",
    "axes[1].grid(True)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig(os.path.join(RESULTS_DIR, f'training_history_{MODEL_ID}.png'), dpi=300, bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "print(f'Training history plot saved to {RESULTS_DIR}/training_history_{MODEL_ID}.png')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6adeea36",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize results\n",
    "generator.eval()\n",
    "with torch.no_grad():\n",
    "    sample_L, sample_ab = next(iter(test_loader))\n",
    "    sample_L, sample_ab = sample_L[:8].to(device), sample_ab[:8].to(device)\n",
    "    fake_ab = generator(sample_L)\n",
    "    \n",
    "    evaluator_viz = ColorimetricEvaluator(device)\n",
    "    pred_rgb = evaluator_viz.lab_to_rgb(sample_L, fake_ab)\n",
    "    target_rgb = evaluator_viz.lab_to_rgb(sample_L, sample_ab)\n",
    "    grayscale = sample_L.cpu().numpy()\n",
    "\n",
    "fig, axes = plt.subplots(3, 8, figsize=(20, 8))\n",
    "for i in range(8):\n",
    "    axes[0, i].imshow(grayscale[i, 0], cmap='gray')\n",
    "    axes[0, i].axis('off')\n",
    "    if i == 0:\n",
    "        axes[0, i].set_title('Grayscale', fontsize=10)\n",
    "    \n",
    "    axes[1, i].imshow(np.clip(pred_rgb[i], 0, 1))\n",
    "    axes[1, i].axis('off')\n",
    "    if i == 0:\n",
    "        axes[1, i].set_title('Colorized', fontsize=10)\n",
    "    \n",
    "    axes[2, i].imshow(np.clip(target_rgb[i], 0, 1))\n",
    "    axes[2, i].axis('off')\n",
    "    if i == 0:\n",
    "        axes[2, i].set_title('Ground Truth', fontsize=10)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig(os.path.join(RESULTS_DIR, f'colorization_results_{MODEL_ID}.png'), dpi=300, bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "print(f'Colorization results saved to {RESULTS_DIR}/colorization_results_{MODEL_ID}.png')"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
